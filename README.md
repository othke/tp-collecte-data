# Car Scrapper

Un outil de scraping pour les sites de vente de voitures, spÃ©cialement conÃ§u pour Albi.ca.

PrÃ©sentation du projet : [Presentation](https://othke.github.io/tp-collecte-data/)

## ğŸš€ Installation

### Installation en mode dÃ©veloppement
```bash
# Cloner le repository
git clone <repository-url>
cd car_scrapper

# Installer en mode dÃ©veloppement
pip install -e .
```

### Installation directe
```bash
pip install .
```

## ğŸ“¦ Structure du projet

```
car_scrapper/
â”œâ”€â”€ car_scrapper/
â”‚   â”œâ”€â”€ __init__.py          # Point d'entrÃ©e du paquet
â”‚   â”œâ”€â”€ models.py            # Classes de donnÃ©es (Car, PageInfo)
â”‚   â”œâ”€â”€ database.py          # Gestionnaire de base de donnÃ©es SQLite
â”‚   â”œâ”€â”€ extractor.py         # Extracteur de donnÃ©es HTML
â”‚   â”œâ”€â”€ navigator.py         # Navigateur web avec Playwright
â”‚   â”œâ”€â”€ scraper.py           # Scraper principal
â”‚   â””â”€â”€ cli.py              # Interface en ligne de commande
â”œâ”€â”€ main.py                  # Script principal
â”œâ”€â”€ setup.py                 # Configuration du paquet
â”œâ”€â”€ requirements.txt         # DÃ©pendances
â””â”€â”€ README.md               # Documentation
```

## ğŸ› ï¸ Utilisation

### Utilisation simple
```python
from car_scrapper import AlbiScraper

# CrÃ©er un scraper
scraper = AlbiScraper()

# Scraper 2 pages Ã  partir de la page 1
scraper.scrap_from_page(1, 2)

# Afficher toutes les voitures de la base de donnÃ©es
scraper.display_all_cars_from_db()
```

### Utilisation en ligne de commande
```bash
# Scraper 1 page
python -m car_scrapper.cli

# Scraper 3 pages Ã  partir de la page 2
python -m car_scrapper.cli --start-page 2 --pages 3

# Afficher toutes les voitures de la base de donnÃ©es
python -m car_scrapper.cli --show-all

# Utiliser une base de donnÃ©es personnalisÃ©e
python -m car_scrapper.cli --db-path my_cars.db
```

### Utilisation comme script
```bash
# ExÃ©cuter le script principal
python main.py
```

### ğŸš€ API REST

Le projet inclut une API REST pour accÃ©der aux donnÃ©es via HTTP.

#### DÃ©marrer le serveur API
```bash
# Serveur par dÃ©faut (port 5000)
python server.py

# Serveur personnalisÃ©
python server.py --host 127.0.0.1 --port 8080 --debug

# Avec base de donnÃ©es personnalisÃ©e
python server.py --db-path my_cars.db
```

#### Endpoints disponibles

**GET /api/cars** - Liste des voitures avec filtres et pagination
```bash
# Toutes les voitures
curl "http://localhost:5000/api/cars"

# Avec pagination
curl "http://localhost:5000/api/cars?page=1&per_page=10"

# Avec filtres
curl "http://localhost:5000/api/cars?make=Mazda&fuel=Ã‰lectrique&price_lt=30000"

# Avec tri
curl "http://localhost:5000/api/cars?sort_by=price&sort_order=desc"
```

**GET /api/cars/{id}** - DÃ©tails d'une voiture
```bash
curl "http://localhost:5000/api/cars/1"
```

**GET /api/stats** - Statistiques de la base de donnÃ©es
```bash
curl "http://localhost:5000/api/stats"
```

#### ParamÃ¨tres de filtrage
- `make` : Marque du vÃ©hicule
- `model` : ModÃ¨le du vÃ©hicule
- `fuel` : Type de carburant (Essence/Ã‰lectrique)
- `price_lt` : Prix infÃ©rieur Ã 
- `price_gt` : Prix supÃ©rieur Ã 
- `year_lt` : AnnÃ©e infÃ©rieure Ã 
- `year_gt` : AnnÃ©e supÃ©rieure Ã 

#### ParamÃ¨tres de pagination
- `page` : NumÃ©ro de page (dÃ©faut: 1)
- `per_page` : Nombre d'Ã©lÃ©ments par page (max: 50, dÃ©faut: 20)

#### ParamÃ¨tres de tri
- `sort_by` : Champ de tri (id, make, model, year, price, mileage, fuel, location)
- `sort_order` : Ordre de tri (asc, desc)

## ğŸ—„ï¸ Base de donnÃ©es

Le scraper utilise SQLite pour stocker les donnÃ©es des voitures. Chaque voiture est identifiÃ©e par son `detail_url` unique.

### Structure de la table `Car` :
- `id` : Identifiant unique
- `make` : Marque du vÃ©hicule
- `model` : ModÃ¨le du vÃ©hicule
- `year` : AnnÃ©e du vÃ©hicule
- `price` : Prix en dollars
- `mileage` : KilomÃ©trage
- `fuel` : Type de carburant (Essence/Ã‰lectrique)
- `location` : Localisation du vÃ©hicule
- `options` : Options du vÃ©hicule (JSON)
- `detail_url` : URL de dÃ©tail (unique)
- `created_at` : Date de crÃ©ation
- `updated_at` : Date de mise Ã  jour

## ğŸ”§ FonctionnalitÃ©s

- âœ… **Scraping automatique** : Extraction des donnÃ©es de voitures
- âœ… **DÃ©tection de carburant** : Identification automatique des vÃ©hicules Ã©lectriques
- âœ… **Base de donnÃ©es SQLite** : Stockage persistant des donnÃ©es
- âœ… **Gestion des doublons** : Mise Ã  jour automatique des donnÃ©es existantes
- âœ… **Interface CLI** : Utilisation en ligne de commande
- âœ… **Affichage tabulaire** : PrÃ©sentation claire des donnÃ©es avec tabulate
- âœ… **Navigation paginÃ©e** : Gestion automatique de la pagination

## ğŸ“‹ DÃ©pendances

- `playwright` : Navigation web automatisÃ©e
- `beautifulsoup4` : Parsing HTML
- `tabulate` : Affichage tabulaire
- `sqlite3` : Base de donnÃ©es (inclus avec Python)
